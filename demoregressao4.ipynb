{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#necessario por causa do metodo de avaliaçao\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "        make_scorer,\n",
    "        confusion_matrix, \n",
    "        cohen_kappa_score, \n",
    "        accuracy_score, \n",
    "        precision_score, \n",
    "        recall_score, \n",
    "        f1_score, \n",
    "        roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier # decision trees for classification\n",
    "from sklearn.neural_network import  MLPClassifier # neural networks for classification\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes for classification\n",
    "from sklearn.svm import SVC # support vector machines for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir as Métricas para Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricas regressao\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def custom_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricas classificação\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metricas regressao\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "REGRESSION_METRICS = {\n",
    "    \"MSE\": make_scorer(mean_squared_error),\n",
    "    \"MAE\": make_scorer(mean_absolute_error),\n",
    "    \"R2\": make_scorer(r2_score)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "        \"accuracy\": make_scorer(accuracy_score),\n",
    "        \"precision\": make_scorer(precision_score),\n",
    "        \"recall\": make_scorer(recall_score),\n",
    "        \"f1\": make_scorer(f1_score),\n",
    "        \"AUC\": make_scorer(roc_auc_score, needs_proba=True),\n",
    "        \"specificity\": make_scorer(specificity_score),\n",
    "        \"kappa\":make_scorer(cohen_kappa_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler o Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_body_type</th>\n",
       "      <th>id_full_name</th>\n",
       "      <th>ano</th>\n",
       "      <th>id_city</th>\n",
       "      <th>id_insurance</th>\n",
       "      <th>seats</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>mileage</th>\n",
       "      <th>id_fuel_type</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>max_power</th>\n",
       "      <th>id_owner_type</th>\n",
       "      <th>resale_price_Lakh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375361</td>\n",
       "      <td>3.237418</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.092066</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>23.84</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>30910.0</td>\n",
       "      <td>83.8</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595820</td>\n",
       "      <td>2.885236</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.290475</td>\n",
       "      <td>1.317034</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>48089.0</td>\n",
       "      <td>88.7</td>\n",
       "      <td>1.357319</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.561640</td>\n",
       "      <td>3.061327</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.915716</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>117.3</td>\n",
       "      <td>0.617152</td>\n",
       "      <td>5.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595820</td>\n",
       "      <td>3.663387</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.915716</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>14.08</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>167.6</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375361</td>\n",
       "      <td>3.441538</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.172025</td>\n",
       "      <td>1.317034</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>61113.0</td>\n",
       "      <td>83.1</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13815</th>\n",
       "      <td>1.360191</td>\n",
       "      <td>3.663387</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.033298</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>14.11</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>197.2</td>\n",
       "      <td>0.617152</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13816</th>\n",
       "      <td>0.375361</td>\n",
       "      <td>3.362357</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.221954</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>18.60</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>17923.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13817</th>\n",
       "      <td>0.561640</td>\n",
       "      <td>3.441538</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.033298</td>\n",
       "      <td>0.436701</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>21.13</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>63389.0</td>\n",
       "      <td>108.6</td>\n",
       "      <td>0.617152</td>\n",
       "      <td>7.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13818</th>\n",
       "      <td>0.595820</td>\n",
       "      <td>2.778780</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.869364</td>\n",
       "      <td>0.436701</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>24.30</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>0.617152</td>\n",
       "      <td>9.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13819</th>\n",
       "      <td>0.561640</td>\n",
       "      <td>2.760297</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.869364</td>\n",
       "      <td>0.436701</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>33046.0</td>\n",
       "      <td>86.7</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13820 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_body_type  id_full_name   ano   id_city  id_insurance  seats  \\\n",
       "0          0.375361      3.237418  2019  1.092066      0.260896    5.0   \n",
       "1          0.595820      2.885236  2018  1.290475      1.317034    5.0   \n",
       "2          0.561640      3.061327  2015  0.915716      0.260896    5.0   \n",
       "3          0.595820      3.663387  2021  0.915716      0.260896    7.0   \n",
       "4          0.375361      3.441538  2019  1.172025      1.317034    5.0   \n",
       "...             ...           ...   ...       ...           ...    ...   \n",
       "13815      1.360191      3.663387  2021  1.033298      0.260896    7.0   \n",
       "13816      0.375361      3.362357  2017  1.221954      0.260896    5.0   \n",
       "13817      0.561640      3.441538  2017  1.033298      0.436701    5.0   \n",
       "13818      0.595820      2.778780  2017  0.869364      0.436701    5.0   \n",
       "13819      0.561640      2.760297  2015  0.869364      0.436701    5.0   \n",
       "\n",
       "       engine_capacity  mileage  id_fuel_type  kms_driven  max_power  \\\n",
       "0               1199.0    23.84      0.186603     30910.0       83.8   \n",
       "1               1199.0    17.50      0.186603     48089.0       88.7   \n",
       "2               1497.0    17.40      0.186603     51000.0      117.3   \n",
       "3               1956.0    14.08      0.500424     30000.0      167.6   \n",
       "4               1197.0    21.40      0.186603     61113.0       83.1   \n",
       "...                ...      ...           ...         ...        ...   \n",
       "13815           2199.0    14.11      0.500424     80000.0      197.2   \n",
       "13816           1197.0    18.60      0.186603     17923.0       81.8   \n",
       "13817           1498.0    21.13      0.500424     63389.0      108.6   \n",
       "13818           1248.0    24.30      0.500424     40000.0       88.5   \n",
       "13819           1198.0    18.00      0.186603     33046.0       86.7   \n",
       "\n",
       "       id_owner_type  resale_price_Lakh  \n",
       "0           0.152217               5.66  \n",
       "1           1.357319               6.64  \n",
       "2           0.617152               5.65  \n",
       "3           0.152217              23.00  \n",
       "4           0.152217               6.87  \n",
       "...              ...                ...  \n",
       "13815       0.617152              26.50  \n",
       "13816       0.152217               5.87  \n",
       "13817       0.617152               7.43  \n",
       "13818       0.617152               9.45  \n",
       "13819       0.152217               4.55  \n",
       "\n",
       "[13820 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(\"Xcenario4.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = d.drop(\"resale_price_Lakh\", axis=1), d[\"resale_price_Lakh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir o Método de Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação\n",
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "# Utilize KFold para um problema de regressão\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação dos Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_MAE</th>\n",
       "      <th>test_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>29.974181</td>\n",
       "      <td>2.948132</td>\n",
       "      <td>0.753871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_MSE  test_MAE   test_R2\n",
       "0  0.034268    0.005011  29.974181  2.948132  0.753871"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Utilize KFold para um problema de regressão\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "# Continue com a validação cruzada e a avaliação de métricas\n",
    "dt_regressor = DecisionTreeRegressor(max_depth=3, random_state=1234)\n",
    "scores = cross_validate(dt_regressor, X, y, cv=kf, scoring=REGRESSION_METRICS)\n",
    "dt_scores = pd.DataFrame(scores)\n",
    "pd.DataFrame(dt_scores.mean()).T\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037531</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall  test_f1  \\\n",
       "0  0.037531    0.014299            NaN             NaN          NaN      NaN   \n",
       "\n",
       "   test_AUC  test_specificity  test_kappa  \n",
       "0       NaN               NaN         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Criar um modelo de regressão de árvore de decisão\n",
    "dt_regressor = DecisionTreeRegressor(max_depth=3, random_state=1234)\n",
    "\n",
    "# Estratégia de validação cruzada (KFold) para um problema de regressão\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "# Continuar com a validação cruzada e avaliação de métricas\n",
    "scores = cross_validate(dt_regressor, X, y, cv=kf, scoring=METRICS)\n",
    "dt_scores = pd.DataFrame(scores)\n",
    "pd.DataFrame(dt_scores.mean()).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\UserHP\\Desktop\\4º ano\\AASE\\repositorio\\AASE\\demoregressao4.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dt \u001b[39m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m splitter \u001b[39m=\u001b[39m StratifiedKFold(\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_validate(dt, X, y, cv\u001b[39m=\u001b[39;49msplitter, scoring\u001b[39m=\u001b[39;49mMETRICS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dt_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(scores)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(dt_scores\u001b[39m.\u001b[39mmean())\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[39m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[1;32m-> 1789\u001b[0m \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m iterable:\n\u001b[0;32m   1790\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_dispatched_batches \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n\u001b[0;32m   1791\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_dispatched_tasks \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;49;00m delayed_func, args, kwargs \u001b[39min\u001b[39;49;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:377\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[0;32m    370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         (\n\u001b[0;32m    372\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    375\u001b[0m     )\n\u001b[1;32m--> 377\u001b[0m \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msplit(X, y, groups):\n\u001b[0;32m    378\u001b[0m     \u001b[39myield\u001b[39;49;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:108\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    107\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m--> 108\u001b[0m \u001b[39mfor\u001b[39;49;00m test_index \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter_test_masks(X, y, groups):\n\u001b[0;32m    109\u001b[0m     train_index \u001b[39m=\u001b[39;49m indices[np\u001b[39m.\u001b[39;49mlogical_not(test_index)]\n\u001b[0;32m    110\u001b[0m     test_index \u001b[39m=\u001b[39;49m indices[test_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:770\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter_test_masks\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 770\u001b[0m     test_folds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_test_folds(X, y)\n\u001b[0;32m    771\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits):\n\u001b[0;32m    772\u001b[0m         \u001b[39myield\u001b[39;00m test_folds \u001b[39m==\u001b[39m i\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:713\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    711\u001b[0m allowed_target_types \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    712\u001b[0m \u001b[39mif\u001b[39;00m type_of_target_y \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_target_types:\n\u001b[1;32m--> 713\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    714\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSupported target types are: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    715\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[0;32m    716\u001b[0m         )\n\u001b[0;32m    717\u001b[0m     )\n\u001b[0;32m    719\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y)\n\u001b[0;32m    721\u001b[0m _, y_idx, y_inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, random_state=1234)\n",
    "splitter = StratifiedKFold(10, random_state=1234, shuffle=True)\n",
    "scores = cross_validate(dt, X, y, cv=splitter, scoring=METRICS)\n",
    "dt_scores = pd.DataFrame(scores)\n",
    "pd.DataFrame(dt_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n    return self._fit(X, y, incremental=False)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 442, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1615, in _validate_input\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nMLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\UserHP\\Desktop\\4º ano\\AASE\\repositorio\\AASE\\demoregressao4.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m nn_regressor \u001b[39m=\u001b[39m MLPRegressor(hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m), max_iter\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Realizar a validação cruzada e avaliar as métricas\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scores_nn \u001b[39m=\u001b[39m cross_validate(nn_regressor, X, y, cv\u001b[39m=\u001b[39;49mkf, scoring\u001b[39m=\u001b[39;49mREGRESSION_METRICS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m nn_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(scores_nn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/UserHP/Desktop/4%C2%BA%20ano/AASE/repositorio/AASE/demoregressao4.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(nn_scores\u001b[39m.\u001b[39mmean())\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n    return self._fit(X, y, incremental=False)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 442, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1615, in _validate_input\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\UserHP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nMLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Criar uma Rede Neural para regressão\n",
    "nn_regressor = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=20, random_state=1234)\n",
    "\n",
    "# Realizar a validação cruzada e avaliar as métricas\n",
    "scores_nn = cross_validate(nn_regressor, X, y, cv=kf, scoring=REGRESSION_METRICS)\n",
    "nn_scores = pd.DataFrame(scores_nn)\n",
    "pd.DataFrame(nn_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.855526</td>\n",
       "      <td>0.00995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall  test_f1  \\\n",
       "0  1.855526     0.00995            NaN             NaN          NaN      NaN   \n",
       "\n",
       "   test_AUC  test_specificity  test_kappa  \n",
       "0       NaN               NaN         NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Criar uma Rede Neural para regressão\n",
    "nn_regressor = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=20, random_state=1234)\n",
    "\n",
    "# Realizar a validação cruzada e avaliar as métricas\n",
    "scores_nn = cross_validate(nn_regressor, X, y, cv=kf, scoring=METRICS)\n",
    "nn_scores = pd.DataFrame(scores_nn)\n",
    "pd.DataFrame(nn_scores.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=20, random_state=1234)\n",
    "scores_nn = cross_validate(nn, X, y, cv=splitter, scoring=METRICS)\n",
    "nn_scores = pd.DataFrame(scores_nn)\n",
    "pd.DataFrame(nn_scores.mean()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_MAE</th>\n",
       "      <th>test_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.975208</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>10.881947</td>\n",
       "      <td>1.376584</td>\n",
       "      <td>0.876171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_MSE  test_MAE   test_R2\n",
       "0  5.975208    0.039888  10.881947  1.376584  0.876171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# Criar um regressor RandomForest\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=1234)\n",
    "\n",
    "# Realizar a validação cruzada e avaliar as métricas\n",
    "scores_rf = cross_validate(rf_regressor, X, y, cv=kf, scoring=REGRESSION_METRICS)\n",
    "rf_scores = pd.DataFrame(scores_rf)\n",
    "pd.DataFrame(rf_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.203438</td>\n",
       "      <td>0.045088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall  test_f1  \\\n",
       "0  6.203438    0.045088            NaN             NaN          NaN      NaN   \n",
       "\n",
       "   test_AUC  test_specificity  test_kappa  \n",
       "0       NaN               NaN         NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# Criar um regressor RandomForest\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=1234)\n",
    "\n",
    "# Realizar a validação cruzada e avaliar as métricas\n",
    "scores_rf = cross_validate(rf_regressor, X, y, cv=kf, scoring=METRICS)\n",
    "rf_scores = pd.DataFrame(scores_rf)\n",
    "pd.DataFrame(rf_scores.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "scores_nb = cross_validate(nb, X, y, cv=splitter, scoring=METRICS)\n",
    "nb_scores = pd.DataFrame(scores_nb)\n",
    "pd.DataFrame(nb_scores.mean()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=1234, probability=True)\n",
    "scores_svm = cross_validate(svm, X, y, cv=splitter, scoring=METRICS)\n",
    "svm_scores = pd.DataFrame(scores_svm)\n",
    "pd.DataFrame(svm_scores.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_MAE</th>\n",
       "      <th>test_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.658228</td>\n",
       "      <td>0.038372</td>\n",
       "      <td>10.881947</td>\n",
       "      <td>1.376584</td>\n",
       "      <td>0.876171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_MSE  test_MAE   test_R2\n",
       "0  5.658228    0.038372  10.881947  1.376584  0.876171"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Criar um regressor RandomForest\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=1234)\n",
    "\n",
    "# Realizar a validação cruzada e avaliar as métricas\n",
    "scores_rf = cross_validate(rf_regressor, X, y, cv=kf, scoring=REGRESSION_METRICS)\n",
    "rf_scores = pd.DataFrame(scores_rf)\n",
    "pd.DataFrame(rf_scores.mean()).T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('aase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "941a02c14a17852a9cb07cad892c4a36ec1d8a3f93fc8ad448615ff7fbd85d7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
